name: inductor-xpu-e2e-test

inputs:
  suite:
    required: true
    type: string
    default: "huggingface"
    description: Dynamo benchmarks test suite, huggingface / timm_models / torchbench
  dt:
    required: true
    type: string
    default: "float32"
    description: Data precision of the test. float32 / bfloat16 / float16 / amp_fp16 / amp_bf16
  mode:
    required: true
    type: string
    default: "inference"
    description: inference / training test
  scenario:
    required: true
    type: string
    default: "accuracy"
    description: accuracy / performance test
  cards:
    required: false
    type: string
    default: "all"
    description: which cards can be used in the test
  expected_pass_num:
    required: false
    type: number
    description: for result check

runs:
  using: composite
  steps:
    - name: E2E Test (${{ inputs.suite }} ${{ inputs.dt }} ${{ inputs.mode }} ${{ inputs.scenario }})
      shell: bash
      run: |
        source activate e2e_ci
        cp .github/scripts/inductor_xpu_test.sh ../pytorch
        cd ../pytorch
        if [[ ${{ input.suite}} == "timm_models" ]]; then
            pip install --no-deps "git+https://github.com/rwightman/pytorch-image-models@b9d43c7dcac1fe05e851dd7be7187b108af593d2"
        elif [[ ${{ input.suite}} == "torchbench" ]]; then
            pip install transformers==4.38.1 --no-deps
            pip install timm==0.9.7 --no-deps
            apt-get update -y
            apt install libgl1-mesa-glx -y
            conda install -y git-lfs pyyaml pandas scipy psutil
            pip install tqdm pandas pyre-extensions torchrec tensorboardX dalle2_pytorch torch_geometric scikit-image matplotlib  gym fastNLP doctr matplotlib opacus python-doctr higher opacus dominate kaldi-io librosa effdet pycocotools diffusers
            pip uninstall -y pyarrow pandas
            pip install pyarrow pandas
            
            cd ..
            git clone https://github.com/facebookresearch/detectron2.git
            python -m pip install -e detectron2

            git clone --recursive https://github.com/facebookresearch/multimodal.git multimodal
            pushd multimodal
            pip install -e .
            popd
        fi

        #TRANSFORMERS_COMMIT=$(cat .ci/docker/ci_commit_pins/huggingface.txt)
        #pip install --force-reinstall git+https://github.com/huggingface/transformers@${TRANSFORMERS_COMMIT}
        source /opt/intel/oneapi/setvars.sh
        #export PYTORCH_ENABLE_XPU_FALLBACK=1
        rm -rf inductor_log
        bash inductor_xpu_test.sh ${{ inputs.suite }} ${{ inputs.dt }} ${{ inputs.mode }} ${{ inputs.scenario }} xpu 3
    - name: Test Results Overview (${{ inputs.suite }} ${{ inputs.dt }} ${{ inputs.mode }} ${{ inputs.scenario }})
      shell: bash
      run: |
        set +e
        cd ../pytorch/inductor_log/${{ inputs.suite }}
        cd ${{ inputs.dt }}
        echo -e "============ Summary for ${{ inputs.suite }} ${{ inputs.dt }} ${{ inputs.mode }} ${{ inputs.scenario }} ============" | tee -a ./${{ inputs.suite }}_${{ inputs.dt }}_${{ inputs.mode }}_${{ inputs.scenario }}_e2e_summary.log
        awk -i inplace '!seen[$0]++' inductor_${{ inputs.suite }}_${{ inputs.dt }}_${{ inputs.mode }}_xpu_${{ inputs.scenario }}.csv
        csv_lines=$(cat inductor_${{ inputs.suite }}_${{ inputs.dt }}_${{ inputs.mode }}_xpu_${{ inputs.scenario }}.csv | wc -l)
        let num_total=csv_lines-1
        num_passed=$(grep -c "pass" inductor_${{ inputs.suite }}_${{ inputs.dt }}_${{ inputs.mode }}_xpu_${{ inputs.scenario }}.csv)
        let num_failed=num_total-num_passed
        pass_rate=`awk 'BEGIN{printf "%.2f%%\n",('$num_passed'/'$num_total')*100}'`
        echo "num_total: $num_total" | tee -a ./${{ inputs.suite }}_${{ inputs.dt }}_${{ inputs.mode }}_${{ inputs.scenario }}_e2e_summary.log
        echo "num_passed: $num_passed" | tee -a ./${{ inputs.suite }}_${{ inputs.dt }}_${{ inputs.mode }}_${{ inputs.scenario }}_e2e_summary.log
        echo "num_failed: $num_failed" | tee -a ./${{ inputs.suite }}_${{ inputs.dt }}_${{ inputs.mode }}_${{ inputs.scenario }}_e2e_summary.log
        echo "pass_rate: $pass_rate" | tee -a ./${{ inputs.suite }}_${{ inputs.dt }}_${{ inputs.mode }}_${{ inputs.scenario }}_e2e_summary.log
        cd ${{ github.workspace }} && cp -r ../pytorch/inductor_log .
    - name: Upload Inductor XPU E2E CI Data (${{ inputs.suite }} ${{ inputs.dt }} ${{ inputs.mode }} ${{ inputs.scenario }})
      uses: actions/upload-artifact@v4
      with:
        name: Inductor-XPU-E2E-CI-Data-${{ inputs.suite }}-${{ inputs.dt }}-${{ inputs.mode }}-${{ inputs.scenario }}-${{ github.event.pull_request.number || github.ref }}
        path: ${{ github.workspace }}/../pytorch/inductor_log
    - name: Test Results Check (${{ inputs.suite }} ${{ inputs.dt }} ${{ inputs.mode }} ${{ inputs.scenario }})
      if: ${{ inputs.expected_pass_num }}
      shell: bash
      run: |
        cd ../pytorch/inductor_log/${{ inputs.suite }}
        cd ${{ inputs.dt }}
        num_passed=$(grep "num_passed:" ${{ inputs.suite }}_${{ inputs.dt }}_${{ inputs.mode }}_${{ inputs.scenario }}_e2e_summary.log | sed -e 's/.*://;s/[^0-9.]//')
        if [ $num_passed -lt ${{ inputs.expected_pass_num }} ]; then
          echo -e "[ERROR] Inductor E2E CI test for ${{ inputs.suite }} ${{ inputs.dt }} ${{ inputs.mode }} passed_num < ${{ inputs.expected_pass_num }}"
          exit 1
        fi
