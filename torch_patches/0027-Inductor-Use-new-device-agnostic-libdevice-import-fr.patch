From 8d8e8e56926996d3fdabd7dcd536236614a57458 Mon Sep 17 00:00:00 2001
From: Stonepia <tong.su@intel.com>
Date: Fri, 7 Jun 2024 16:25:52 +0800
Subject: [PATCH 27/39] [Inductor]: Use new device-agnostic libdevice import
 from triton.language (#255)

Modified from pytorch/pytorch#127348.
---
 torch/_inductor/triton_helpers.py | 40 ++++++++++++++++++++++---------
 1 file changed, 29 insertions(+), 11 deletions(-)

diff --git a/torch/_inductor/triton_helpers.py b/torch/_inductor/triton_helpers.py
index 3930d0dd7f2..8f7168cdec5 100644
--- a/torch/_inductor/triton_helpers.py
+++ b/torch/_inductor/triton_helpers.py
@@ -1,18 +1,36 @@
-import triton
-import triton.language as tl
+try:
+    import triton
+    import triton.language as tl
+except ImportError:
+
+    class triton:  # type: ignore[no-redef]
+        @staticmethod
+        def jit(x):
+            return x
+
+    class tl:  # type: ignore[no-redef]
+        constexpr = None  # type: ignore[var-annotated]
+        math = None  # type: ignore[var-annotated]
+        extra = None  # type: ignore[var-annotated]
+
 
 # In the latest triton, math functions were shuffled around into different modules:
 # https://github.com/openai/triton/pull/3172
-if hasattr(tl.extra, "cuda") and hasattr(tl.extra.cuda, "libdevice"):
-    libdevice = tl.extra.cuda.libdevice
-    math = tl.math
-elif hasattr(tl.extra, "intel") and hasattr(tl.extra.intel, "libdevice"):
-    libdevice = tl.extra.intel.libdevice
-    math = tl.math
-else:
-    libdevice = tl.math
-    math = tl
+try:
+    from triton.language.extra import libdevice
 
+    libdevice = tl.extra.libdevice  # noqa: F811
+    math = tl.math
+except ImportError:
+    if hasattr(tl.extra, "cuda") and hasattr(tl.extra.cuda, "libdevice"):
+        libdevice = tl.extra.cuda.libdevice
+        math = tl.math
+    elif hasattr(tl.extra, "intel") and hasattr(tl.extra.intel, "libdevice"):
+        libdevice = tl.extra.intel.libdevice
+        math = tl.math
+    else:
+        libdevice = tl.math
+        math = tl.math
 
 @triton.jit
 def promote_to_tensor(x):
-- 
2.34.1

