From 1c122af900de226d2324b789a5c9864870640b5d Mon Sep 17 00:00:00 2001
From: "Cui, Yifeng" <yifeng.cui@intel.com>
Date: Thu, 11 Apr 2024 14:00:06 +0800
Subject: [PATCH 30/31] Allocate a temporary output tensor for linalg_eigvals on
 Non-CPU device (#226) (#230)

Cherry pick from https://github.com/pytorch/pytorch/pull/116682
---
 aten/src/ATen/native/BatchLinearAlgebra.cpp | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/aten/src/ATen/native/BatchLinearAlgebra.cpp b/aten/src/ATen/native/BatchLinearAlgebra.cpp
index 4d0c9fa8ad4..a760c85977b 100644
--- a/aten/src/ATen/native/BatchLinearAlgebra.cpp
+++ b/aten/src/ATen/native/BatchLinearAlgebra.cpp
@@ -3081,7 +3081,7 @@ Tensor& linalg_eigvals_out(const Tensor& input, Tensor& values) {
 
   // because MAGMA's GEEV takes CPU inputs and returns CPU outputs
   // 'values' tensor that is on GPU device can't be used directly
-  values_tmp_needed |= values.is_cuda();
+  values_tmp_needed |= (!values.is_cpu());
 
   // determine the appropriate scalar_type for the temporary tensors
   ScalarType values_type = input.scalar_type();
-- 
2.34.1

