From cdcfc15e095f5112d97a7a84e8b4c95c319b3a09 Mon Sep 17 00:00:00 2001
From: zejun <zejun.chen@intel.com>
Date: Wed, 19 Jun 2024 16:09:50 +0800
Subject: [PATCH 29/39] [fix][profiler] using end_us to get time stamp from
 backend kineto (#261)

to avoid the missing carry when ns2us for negative cpu time issue

Signed-off-by: Chen, Zejun <zejun.chen@intel.com>
---
 torch/autograd/profiler.py              | 4 ++--
 torch/csrc/autograd/init.cpp            | 2 ++
 torch/csrc/autograd/profiler_kineto.cpp | 4 ++++
 torch/csrc/autograd/profiler_kineto.h   | 1 +
 4 files changed, 9 insertions(+), 2 deletions(-)

diff --git a/torch/autograd/profiler.py b/torch/autograd/profiler.py
index 16ee88fdb13..96764daa9e4 100644
--- a/torch/autograd/profiler.py
+++ b/torch/autograd/profiler.py
@@ -445,8 +445,8 @@ class profile:
             if _filter_name(kineto_event.name()):
                 continue
             rel_start_us = kineto_event.start_us() - trace_start_us
-            rel_end_us = rel_start_us + kineto_event.duration_us()
-            abs_end_us = kineto_event.start_us() + kineto_event.duration_us()
+            rel_end_us = kineto_event.end_us() - trace_start_us
+            abs_end_us = kineto_event.end_us()
 
             cpu_memory_usage = 0
             device_memory_usage = 0
diff --git a/torch/csrc/autograd/init.cpp b/torch/csrc/autograd/init.cpp
index b4e21016715..67b8cad342d 100644
--- a/torch/csrc/autograd/init.cpp
+++ b/torch/csrc/autograd/init.cpp
@@ -203,6 +203,8 @@ PyObject* THPAutograd_initExtension(PyObject* _unused, PyObject* unused) {
       .def("sequence_nr", [](const KinetoEvent& e) { return e.sequenceNr(); })
       // absolute start time (since unix epoch) in us
       .def("start_us", [](const KinetoEvent& e) { return e.startUs(); })
+      // absolute end time (since unix epoch) in us
+      .def("end_us", [](const KinetoEvent& e) { return e.endUs(); })
       // duration in us
       .def("duration_us", [](const KinetoEvent& e) { return e.durationUs(); })
       // used for correlation between high-level PyTorch events
diff --git a/torch/csrc/autograd/profiler_kineto.cpp b/torch/csrc/autograd/profiler_kineto.cpp
index 350db179427..de790279b62 100644
--- a/torch/csrc/autograd/profiler_kineto.cpp
+++ b/torch/csrc/autograd/profiler_kineto.cpp
@@ -774,6 +774,10 @@ uint64_t KinetoEvent::durationUs() const {
   return (result_->endTimeNS() - result_->start_time_ns_) / 1000;
 }
 
+uint64_t KinetoEvent::endUs() const {
+  return result_->endTimeNS() / 1000;
+}
+
 int64_t KinetoEvent::debugHandle() const {
   return result_->visit(c10::overloaded(
       [](const ExtraFields<EventType::TorchOp>& i) { return i.debug_handle_; },
diff --git a/torch/csrc/autograd/profiler_kineto.h b/torch/csrc/autograd/profiler_kineto.h
index 6ea7cf63d6a..d38aec2d3c2 100644
--- a/torch/csrc/autograd/profiler_kineto.h
+++ b/torch/csrc/autograd/profiler_kineto.h
@@ -49,6 +49,7 @@ struct TORCH_API KinetoEvent {
   int deviceIndex() const;
   int64_t nBytes() const;
   uint64_t startUs() const;
+  uint64_t endUs() const;
   uint64_t durationUs() const;
   bool isAsync() const;
   uint64_t correlationId() const;
-- 
2.34.1

